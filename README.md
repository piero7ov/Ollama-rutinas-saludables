# ü•ó Ollama ‚Äì Rutinas Saludables (PHP + IA local)

App web en **PHP** que genera una **rutina de ejercicios semanal** usando **Ollama** (IA corriendo en tu PC).  
Funciona en local: un formulario manda tus ‚Äútipos de ejercicios‚Äù ‚Üí PHP arma un prompt ‚Üí Ollama responde ‚Üí la web muestra la rutina.

Repo: https://github.com/piero7ov/ollama-rutinas-saludables

---

## ‚ú® Qu√© hace

- Formulario para ingresar **5 tipos de ejercicios** (ej: ‚Äúcardio‚Äù, ‚Äúyoga‚Äù, ‚Äúfuerza‚Äù‚Ä¶)
- Genera una rutina de **Lunes a Domingo**
- Llama a la API local de Ollama: `http://localhost:11434/api/generate` :contentReference[oaicite:0]{index=0}
- Puedes elegir **qu√© modelo (IA) usar**: llama3, qwen, mistral, gemma, etc. (siempre que lo tengas descargado en Ollama) :contentReference[oaicite:1]{index=1}

---

## üìÅ Archivos principales

- `003-formulario de toma de datos.php` ‚Üí formulario (entrada)
- `004-calculaejercicios.php` ‚Üí llama a Ollama y muestra la rutina (salida)

Extras / pruebas:
- `005-probamos qwen.php` ‚Üí ejemplo usando otro modelo (`qwen2.5-coder:7b`)
- `001/002` ‚Üí iteraciones de prompts
- `006-tipos de ejercicios.md` ‚Üí ideas para rellenar el formulario

---

## ‚úÖ Requisitos

- **Servidor con PHP** (recomendado: **XAMPP** en Windows)
- PHP con **cURL** habilitado
- **Ollama instalado**
- **Al menos 1 modelo descargado** en Ollama (esto es clave)

> Ojo: los modelos ocupan bastante espacio (decenas de GB en algunos casos). :contentReference[oaicite:2]{index=2}

---

## üöÄ Quick start (en 5 pasos)

1) Instala Ollama (Windows o Linux, abajo tienes mini tutorial). :contentReference[oaicite:3]{index=3}  
2) Descarga un modelo: `ollama pull llama3:latest` :contentReference[oaicite:4]{index=4}  
3) Copia el proyecto a tu servidor web (ej: `htdocs` en XAMPP).  
4) Abre el formulario: `003-formulario de toma de datos.php`  
5) Rellena los 5 tipos ‚Üí **Generar Rutina** ‚úÖ

---

## üß† Mini tutorial: Instalar Ollama + ‚Äúsus IAs‚Äù (modelos)

### ü™ü Windows

1) Descarga e instala **Ollama para Windows** (instalador oficial). :contentReference[oaicite:5]{index=5}  
2) Abre **PowerShell** o **CMD** y verifica:
```bash
ollama --version
````

3. Descarga (instala) un modelo:

```bash
ollama pull llama3:latest
```

4. Prueba que responde:

```bash
ollama run llama3:latest
```

5. Ver modelos descargados:

```bash
ollama list
```

([GitHub][1])

> Tip: en Windows, normalmente Ollama queda corriendo en segundo plano y la API local queda disponible.

---

### üêß Linux (Ubuntu/Debian y similares)

1. Instalar Ollama (script oficial):

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

([docs.ollama.com][2])

2. Levantar el servicio (opci√≥n r√°pida):

```bash
ollama serve
```

([docs.ollama.com][3])

3. Descargar un modelo:

```bash
ollama pull llama3:latest
```

4. Probar:

```bash
ollama run llama3:latest
```

5. Ver modelos descargados:

```bash
ollama list
```

([GitHub][1])

> Opcional (modo servidor): puedes configurar Ollama como servicio systemd. La doc oficial explica el `ollama serve` y el enfoque de servicio. ([docs.ollama.com][3])

---

## üéõÔ∏è Elegir qu√© modelo (IA) usa el proyecto

En `004-calculaejercicios.php` cambia esta l√≠nea:

```php
"model" => "llama3:latest",
```

Por el modelo que tengas instalado (m√≠ralo con `ollama list`), por ejemplo:

* `"model" => "qwen2.5-coder:7b",`
* `"model" => "llama3.2:latest",`

Si pones un nombre que no existe en tu PC, te va a fallar o no va a responder.

---

## üß∞ Instalaci√≥n del proyecto (XAMPP recomendado)

### Windows + XAMPP

1. Copia la carpeta del proyecto a:

* `C:\xampp\htdocs\ollama-rutinas-saludables\`

2. En XAMPP, enciende:

* ‚úÖ Apache

3. Aseg√∫rate de que Ollama est√© corriendo y tengas un modelo descargado.

4. Abre en el navegador:

* `http://localhost/ollama-rutinas-saludables/003-formulario%20de%20toma%20de%20datos.php`

> Si te incomodan los espacios en nombres de archivos, puedes renombrarlos (opcional), pero as√≠ como est√° funciona.

---

## üßØ Problemas comunes

**1) ‚ÄúError al conectar con la IA‚Äù**

* Ollama no est√° corriendo (`ollama serve` en Linux o app activa en Windows)
* Puerto/API no disponible: `http://localhost:11434` ([docs.ollama.com][4])

**2) No tienes modelos descargados**

* Soluci√≥n:

```bash
ollama pull llama3:latest
ollama list
```

([GitHub][1])

**3) Entraste directo a `004-calculaejercicios.php`**

* Ese archivo espera `POST` del formulario.

---

## üîí Nota r√°pida (uso responsable)

La rutina generada es texto autom√°tico. √ösalo como gu√≠a general y ajusta a tu contexto.

---

## üë§ Autor

Piero Olivares
[3]: https://docs.ollama.com/cli?utm_source=chatgpt.com "CLI Reference"
[4]: https://docs.ollama.com/api/authentication?utm_source=chatgpt.com "Authentication"
